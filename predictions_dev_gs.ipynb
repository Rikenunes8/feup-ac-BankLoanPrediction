{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv('data_processed/complete/data_selected.csv')\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    return df.drop(['status', 'loan_id'], axis=1)\n",
    "def get_target(df):\n",
    "    return df['status']\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_X_train, _X_test, _y_train, _y_test = train_test_split(get_features(data), get_target(data), test_size=0.25, random_state=11, stratify=get_target(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "\n",
    "\n",
    "stratified_kfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec, pyplot as plt\n",
    "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sb\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "def grid_search(name, pipeline, param_grid):\n",
    "    grid_search = GridSearchCV(estimator=pipeline,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='roc_auc',\n",
    "                            cv=stratified_kfold,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(_X_train, _y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    test_score = grid_search.score(_X_test, _y_test)\n",
    "    print(f'Cross-validation score: {best_score}\\nTest score: {test_score}')\n",
    "\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "    sb.histplot(data=grid_search.cv_results_, x='mean_test_score', kde=True, ax=ax)\n",
    "    ax = plt.subplot(gs[0, 1])\n",
    "    sb.boxplot(data=grid_search.cv_results_, x='mean_test_score', ax=ax)\n",
    "    ax = plt.subplot(gs[1, 0])\n",
    "    RocCurveDisplay.from_estimator(grid_search, _X_test, _y_test, ax=ax)\n",
    "    ax = plt.subplot(gs[1, 1])\n",
    "    PrecisionRecallDisplay.from_estimator(best_estimator, _X_test, _y_test, ax=ax)\n",
    "    \n",
    "    with open('grid_search_results/'+name+'_'+str(datetime.timestamp(datetime.now()))+'.json', 'w') as f:\n",
    "        json.dump({'best_params': str(best_params), 'best_score': best_score}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(classifier, smote = False, scaler = None):\n",
    "    steps = []\n",
    "    if smote: steps.append(['smote', SMOTE(random_state=11)])\n",
    "    if scaler: steps.append(['scaler', scaler])\n",
    "    steps.append(['classifier', classifier])\n",
    "    return imbpipeline(steps = steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH = True\n",
    "smote = True\n",
    "scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "if SEARCH:\n",
    "    grid_search('dtc',\n",
    "        make_pipeline(\n",
    "            DecisionTreeClassifier(),\n",
    "            smote=smote,\n",
    "            scaler=scaler\n",
    "        ),\n",
    "        param_grid={\n",
    "            'classifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'classifier__max_depth': [None, 5, 7, 11, 13, 17, 21, 35],\n",
    "            'classifier__min_samples_split': [2, 4, 6, 8, 10, 20],\n",
    "            'classifier__min_samples_leaf': [1, 2, 3, 4, 5, 7, 9, 10],\n",
    "            'classifier__max_features': [None,'sqrt', 'log2'],\n",
    "            'classifier__max_leaf_nodes': [None, 5, 7, 11, 13, 17, 21, 35],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "if SEARCH:\n",
    "    grid_search('knn',\n",
    "        make_pipeline(\n",
    "            KNeighborsClassifier(),\n",
    "            smote=smote,\n",
    "            scaler=scaler\n",
    "        ),\n",
    "        param_grid={\n",
    "            'classifier__n_neighbors': [1, 3, 5, 7, 9, 11],\n",
    "            'classifier__weights': ['uniform', 'distance'],\n",
    "            'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "if SEARCH and False:\n",
    "    grid_search('mlp',\n",
    "        make_pipeline(\n",
    "            MLPClassifier(),\n",
    "            smote=smote,\n",
    "            scaler=scaler\n",
    "        ),\n",
    "        param_grid={\n",
    "            \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "if SEARCH and False:\n",
    "    grid_search('gnb',\n",
    "        make_pipeline(\n",
    "            GaussianNB(),\n",
    "            smote=smote,\n",
    "            scaler=scaler\n",
    "        ),\n",
    "        param_grid={\n",
    "            \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "if SEARCH:\n",
    "    grid_search('svc',\n",
    "        make_pipeline(\n",
    "            SVC(probability=True, max_iter=10000),\n",
    "            smote=smote,\n",
    "            scaler=StandardScaler()\n",
    "        ),\n",
    "        param_grid={\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'classifier__degree': [1, 2, 3, 5, 7],\n",
    "            'classifier__gamma': ['scale', 'auto'],\n",
    "            'classifier__coef0': [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "            'classifier__shrinking': [True, False],\n",
    "            'classifier__tol': [0.01, 0.001, 0.0001],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "if SEARCH:\n",
    "    grid_search('lr',\n",
    "        make_pipeline(\n",
    "            LogisticRegression(max_iter=10000),\n",
    "            smote=smote,\n",
    "            scaler=scaler\n",
    "        ),\n",
    "        param_grid={\n",
    "            'classifier__tol': [0.001, 0.0001, 0.00001],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'classifier__fit_intercept': [True, False],\n",
    "            'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "if SEARCH:\n",
    "    grid_search('rf',\n",
    "        make_pipeline(\n",
    "            RandomForestClassifier(),\n",
    "            smote=smote,\n",
    "            scaler=scaler\n",
    "        ),\n",
    "        param_grid={\n",
    "            'classifier__n_estimators': [40, 75, 100, 150, 200],\n",
    "            'classifier__criterion': [\"gini\", \"entropy\"],\n",
    "            'classifier__max_depth': np.arange(2, 30, 2),\n",
    "            'classifier__max_features': [\"sqrt\", \"log2\", None],\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
