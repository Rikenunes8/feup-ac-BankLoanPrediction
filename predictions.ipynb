{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv('data_processed/data.csv')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary features (Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ids = [c for c in data.columns if c[-3:] != '_id' and c != 'code']\n",
    "data = data[no_ids]\n",
    "# data.drop(['account_frequency', 'gender', 'card_type'], axis=1, inplace=True)\n",
    "\n",
    "display(data.head())\n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    return df.drop('status', axis=1)\n",
    "def get_target(df):\n",
    "    return df.drop(df.columns.difference(['status']), axis=1)\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df, columns):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    le = OrdinalEncoder()\n",
    "    cols = [col for col in columns if col in df.keys()]\n",
    "    df[cols] = le.set_params(encoded_missing_value=-1).fit_transform(df[cols])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = list(data.select_dtypes(\"object\").columns)\n",
    "data = encode_data(data, categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features, target, test_size=0.25, random_state=1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data shape:',data.shape)\n",
    "print('Status  1:',data[data['status']==1].shape)\n",
    "print('Status -1:',data[data['status']==-1].shape)\n",
    "\n",
    "_X_train, _X_test, _y_train, _y_test = split_data(get_features(data), get_target(data))\n",
    "\n",
    "print('\\nTrain shape:',_y_train.shape)\n",
    "print('Status ratio:',_y_train[_y_train['status']==1].shape[0],'|',_y_train[_y_train['status']==-1].shape[0])\n",
    "\n",
    "print('\\nTest shape:',_y_test.shape)\n",
    "print('Status ration:',_y_test[_y_test['status']==1].shape[0],'|',_y_test[_y_test['status']==-1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(X_train, y_train):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE(random_state=1, sampling_strategy=1.0)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_smote_X_train, _smote_y_train = oversample(_X_train, _y_train)\n",
    "\n",
    "print('\\nTrain shape:',_smote_y_train.shape)\n",
    "print('Status ratio:',_smote_y_train[_smote_y_train['status']==1].shape[0],'|',_smote_y_train[_smote_y_train['status']==-1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_test, scaler):\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def standardize_data(X_train, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    return normalize_data(X_train, X_test, StandardScaler())\n",
    "def min_max_scaling(X_train, X_test):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    return normalize_data(X_train, X_test, MinMaxScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model(name, model, use_smote=False):\n",
    "    X_train = _X_train.copy()\n",
    "    X_test = _X_test.copy()\n",
    "    smote_X_train = _smote_X_train.copy()\n",
    "    if (name == 'dtc'):\n",
    "        X_train.drop(['age_on_loan_request_disc'], inplace=True, axis=1)\n",
    "        X_test.drop(['age_on_loan_request_disc'], inplace=True, axis=1)\n",
    "        smote_X_train.drop(['age_on_loan_request_disc'], inplace=True, axis=1)\n",
    "    else:\n",
    "        X_train.drop(['age_on_loan_request'], inplace=True, axis=1)\n",
    "        X_test.drop(['age_on_loan_request'], inplace=True, axis=1)\n",
    "        smote_X_train.drop(['age_on_loan_request'], inplace=True, axis=1)\n",
    "        \n",
    "    # Scaling Normalizations\n",
    "    # X_train, X_test = standardize_data(X_train, X_test)\n",
    "    # X_train, X_test = min_max_scaling(X_train, X_test)\n",
    "\n",
    "    if use_smote: model.fit(smote_X_train, np.ravel(_smote_y_train.values))\n",
    "    else: model.fit(X_train, np.ravel(_y_train.values))\n",
    "    \n",
    "    results[name] = {'model': model, \n",
    "                    'X_train': X_train, \n",
    "                    'X_test': X_test, \n",
    "                    'y_train': np.ravel(_y_train.values), \n",
    "                    'y_test': np.ravel(_y_test.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "add_model('dtc',\n",
    "    DecisionTreeClassifier(),\n",
    "    use_smote=SMOTE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "add_model('knn',\n",
    "    KNeighborsClassifier(),\n",
    "    use_smote=SMOTE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "add_model('mlp',\n",
    "    MLPClassifier(),\n",
    "    use_smote=SMOTE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "add_model('gnb',\n",
    "    GaussianNB(),\n",
    "    use_smote=SMOTE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "add_model('svc',\n",
    "    SVC(probability=True),\n",
    "    use_smote=SMOTE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "add_model('rf',\n",
    "    RandomForestClassifier(),\n",
    "    use_smote=SMOTE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model_rs(name, model, space={}):\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    X = get_features(data)\n",
    "    y = np.ravel(get_target(data).values)\n",
    "    if (name == 'dtc'):\n",
    "        X.drop(['age_on_loan_request_disc'], inplace=True, axis=1)\n",
    "    else:\n",
    "        X.drop(['age_on_loan_request'], inplace=True, axis=1)\n",
    "        \n",
    "    # Scaling Normalizations\n",
    "    # X_train, X_test = standardize_data(X_train, X_test)\n",
    "    # X_train, X_test = min_max_scaling(X_train, X_test)\n",
    "\n",
    "    search = RandomizedSearchCV(model, space, n_iter=500, scoring='roc_auc', n_jobs=-1, random_state=0, cv=5)\n",
    "    search.fit(X, y)\n",
    "    results[name] = {# 'search': search.best_estimator_,\n",
    "                    'best_params': search.best_params_,\n",
    "                    'best_score': search.best_score_}\n",
    "                    #'X': X,\n",
    "                    #'y': y}\n",
    "    with open('random_search_results/'+name+'_'+str(datetime.timestamp(datetime.now()))+'.json', 'w') as f:\n",
    "        json.dump(results[name], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "if SEARCH:\n",
    "    add_model_rs('dtc',\n",
    "        DecisionTreeClassifier(),\n",
    "        space={\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "            'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "            'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "if SEARCH:\n",
    "    add_model_rs('knn',\n",
    "        KNeighborsClassifier(),\n",
    "        space={\n",
    "            'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "if SEARCH:\n",
    "    add_model_rs('mlp',\n",
    "        MLPClassifier(),\n",
    "        space={\n",
    "            \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "if SEARCH:\n",
    "    add_model_rs('gnb',\n",
    "        GaussianNB(),\n",
    "        space={\n",
    "            \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "if SEARCH:\n",
    "    add_model_rs('svc',\n",
    "        SVC(probability=True),\n",
    "        space={\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'coef0': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'shrinking': [True, False],\n",
    "            'probability': [True],\n",
    "            'tol': [0.001, 0.0001, 0.00001],\n",
    "            'cache_size': [200],\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'verbose': [False],\n",
    "            'max_iter': [-1],\n",
    "            'decision_function_shape': ['ovo', 'ovr'],\n",
    "            'break_ties': [False],\n",
    "            'random_state': [None],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "if SEARCH:\n",
    "    add_model_rs('rf',\n",
    "        RandomForestClassifier(),\n",
    "        space={\n",
    "            'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "            'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "            'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "            'bootstrap': [True, False],\n",
    "            'oob_score': [False],\n",
    "            'n_jobs': [-1],\n",
    "            'random_state': [None],\n",
    "            'verbose': [0],\n",
    "            'warm_start': [False],\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'ccp_alpha': [0.0],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(name, isTrain=False):\n",
    "    prefix = 'train' if isTrain else 'test'\n",
    "    result = results[name]\n",
    "    pred = result['model'].predict(result['X_'+prefix])\n",
    "    result[prefix+'pred'] = pred\n",
    "\n",
    "for name in results.keys():\n",
    "    predict(name)\n",
    "for name in results.keys():\n",
    "    predict(name, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(name, isTrain=False):\n",
    "    prefix = 'train' if isTrain else 'test'\n",
    "    result = results[name]\n",
    "    proba = result['model'].predict_proba(result['X_'+prefix])\n",
    "    result[prefix+'pred_prob'] = proba\n",
    "\n",
    "for name in results.keys():\n",
    "    predict_proba(name)\n",
    "for name in results.keys():\n",
    "    predict_proba(name, isTrain=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(cm, i):\n",
    "    return cm[i][i]/sum(cm[i]) if sum(cm[i]) > 0 else np.inf\n",
    "\n",
    "def precision(cm, i):\n",
    "    cmt = np.copy(cm).transpose()\n",
    "    return cm[i][i]/sum(cmt[i]) if sum(cmt[i]) > 0 else np.inf\n",
    "\n",
    "def f_measure(cm, i):\n",
    "    p = precision(cm, i)*100\n",
    "    r = recall(cm, i)*100\n",
    "    return 2 * (p * r) / (p + r) if p != np.inf and r != np.inf and p + r > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.figure import Figure\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "def conf_matrix(y_test, y_pred, name, prefix):\n",
    "    cm =  confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=['True', 'False'])\n",
    "    disp.plot()\n",
    "    disp.ax_.set_title(name + ' ' + prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(name, isTrain=False):\n",
    "    prefix = 'train' if isTrain else 'test'\n",
    "    result = results[name]\n",
    "    result[prefix+'score'] = result['model'].score(result['X_'+prefix], result['y_'+prefix])\n",
    "    print(name.upper()+\":\\t\", result[prefix+'score'])\n",
    "\n",
    "print('\\tAccuracy')\n",
    "print(\"Test\")\n",
    "for name in results.keys():\n",
    "    score(name)\n",
    "print(\"\\nTrain\")\n",
    "for name in results.keys():\n",
    "    score(name, isTrain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall and F-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(name, isTrain=False):\n",
    "    prefix = 'train' if isTrain else 'test'\n",
    "    result = results[name]\n",
    "    cm =  confusion_matrix(result['y_'+prefix], result[prefix+'pred'])\n",
    "    print(prefix, name.upper()+\":\", '\\tRecall:',round(recall(cm, 0), 2), '\\t Precision:',round(precision(cm, 0), 2), '\\tF_Measure:',round(f_measure(cm, 0), 2))\n",
    "\n",
    "print('Test')\n",
    "for name in results.keys():\n",
    "    evaluate(name)\n",
    "print('\\nTrain')\n",
    "for name in results.keys():\n",
    "    evaluate(name, isTrain=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.50\n",
    "\n",
    "prefixes = ('test', 'train')\n",
    "for prefix in prefixes[:1]:\n",
    "    for name in results.keys():\n",
    "        result = results[name]\n",
    "        prefix = 'test'\n",
    "        conf_matrix(result['y_'+prefix], np.where(result[prefix+'pred_prob'][:,-1] > prob, 1, -1), name, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, RocCurveDisplay, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def roc_and_auc(name, isTrain=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    for prefix in ('test', 'train'):\n",
    "        result = results[name]\n",
    "        fpr, tpr, thresholds = roc_curve(result['y_'+prefix], result[prefix+'pred_prob'][:,0], pos_label=result['model'].classes_[0])\n",
    "        roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=ax,name=(name.upper()+' '+prefix))\n",
    "        print(name.upper(), prefix + \":\\t\", auc(fpr, tpr))\n",
    "\n",
    "for name in results.keys():\n",
    "    roc_and_auc(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
