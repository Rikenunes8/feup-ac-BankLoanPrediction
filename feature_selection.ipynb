{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv('data_processed/complete/enc_data.csv')\n",
    "\n",
    "_data = data.copy()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "display(data.head())\n",
    "\n",
    "SELECT_WRAPPED = True\n",
    "REMOVE_HIGH_CORRELATED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    return df.drop('status', axis=1)\n",
    "def get_target(df):\n",
    "    return df.drop(df.columns.difference(['status']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove high correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_HIGH_CORRELATED:\n",
    "    cor_matrix = data.corr().abs()\n",
    "    display(cor_matrix)\n",
    "\n",
    "    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n",
    "    display(upper_tri)\n",
    "\n",
    "    cols = list(upper_tri.columns)\n",
    "    cols.reverse()\n",
    "    to_drop = [column for column in cols if any(upper_tri[column] > 0.80)]\n",
    "    display(to_drop)\n",
    "\n",
    "    data.drop(to_drop, axis=1, inplace=True)\n",
    "    display(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ids = [c for c in data.columns if c[-3:] != '_id' and c != 'code']\n",
    "data = data[no_ids]\n",
    "# data.drop(['account_frequency', 'gender', 'card_type'], axis=1, inplace=True)\n",
    "\n",
    "display(data.head())\n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def make_pipeline(classifier, smote = False, scaler = None):\n",
    "    steps = []\n",
    "    if smote: steps.append(['smote', SMOTE(random_state=11)])\n",
    "    if scaler: steps.append(['scaler', scaler])\n",
    "    steps.append(['classifier', classifier])\n",
    "    return imbpipeline(steps = steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = make_pipeline(RandomForestClassifier(), smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "### Wrapper Method\n",
    "Split Data into subsets and train a model using this. Based on the output of the model, add or subtract features and train the model again.\n",
    "#### 1. Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = get_features(data)\n",
    "y = data['status']\n",
    "\n",
    "def forward_selection(features, target, k_features = 20):\n",
    "    sfs = SFS(estimator,\n",
    "              k_features=k_features,\n",
    "              forward=True,\n",
    "              floating=False,\n",
    "              cv = 5,\n",
    "              scoring = 'roc_auc',\n",
    "              n_jobs = -1)\n",
    "    sfs = sfs.fit(features, target)\n",
    "    fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev')\n",
    "    plt.title('Sequential Forward Selection')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "if SELECT_WRAPPED:\n",
    "    forward_selection_result = forward_selection(x, y)\n",
    "    forward_selection_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def backward_selection(features, target, k_features = 1):\n",
    "    sbs = SFS(estimator,\n",
    "              k_features=k_features,\n",
    "              forward=False,\n",
    "              floating=False,\n",
    "              scoring = 'roc_auc',\n",
    "              cv = 5,\n",
    "              n_jobs = -1)\n",
    "    sbs = sbs.fit(features, target)\n",
    "    fig1 = plot_sfs(sbs.get_metric_dict(), kind='std_dev')\n",
    "    plt.title('Backward Elimination')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return pd.DataFrame.from_dict(sbs.get_metric_dict()).T\n",
    "\n",
    "if SELECT_WRAPPED:\n",
    "    backward_selection_result = backward_selection(x, y)\n",
    "    backward_selection_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Bi-directional Elimination (Step-wise Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bi_directional_elimination(features, target, k_features = (1,20)):\n",
    "    sffs = SFS(estimator,\n",
    "              k_features=k_features,\n",
    "              forward=True,\n",
    "              floating=True,\n",
    "              scoring = 'roc_auc',\n",
    "              cv = 5,\n",
    "              n_jobs = -1)\n",
    "    sffs = sffs.fit(features, target)\n",
    "    fig1 = plot_sfs(sffs.get_metric_dict(), kind='std_dev')\n",
    "    plt.title('Bi-directional Elimination')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return pd.DataFrame.from_dict(sffs.get_metric_dict()).T\n",
    "\n",
    "if SELECT_WRAPPED:\n",
    "    bi_directional_elimination_result = bi_directional_elimination(x, y)\n",
    "    bi_directional_elimination_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the methods\n",
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECT_WRAPPED:\n",
    "    # Change 'avg_score' to float\n",
    "    forward_selection_result['avg_score'] = forward_selection_result['avg_score'].astype(float)\n",
    "    backward_selection_result['avg_score'] = backward_selection_result['avg_score'].astype(float)\n",
    "    bi_directional_elimination_result['avg_score'] = bi_directional_elimination_result['avg_score'].astype(float)\n",
    "\n",
    "    # Find the best result for each method\n",
    "    a = forward_selection_result.iloc[forward_selection_result['avg_score'].idxmax()]\n",
    "    b = backward_selection_result.iloc[backward_selection_result['avg_score'].idxmax()]\n",
    "    c = bi_directional_elimination_result.iloc[bi_directional_elimination_result['avg_score'].idxmax()]\n",
    "\n",
    "    c_df = pd.DataFrame({\n",
    "        'method': ['forward selection', 'backward elimination', 'bi-directional'],\n",
    "        'feature_names': [a['feature_names'], b['feature_names'], c['feature_names']],\n",
    "        'n_features': [len(a['feature_names']), len(b['feature_names']), len(c['feature_names'])],\n",
    "        'avg_score': [a['avg_score'], b['avg_score'], c['avg_score']]  \n",
    "    })\n",
    "\n",
    "    display(c_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECT_WRAPPED:\n",
    "    best_features_names = c_df.iloc[c_df['avg_score'].idxmax()]['feature_names']\n",
    "    print('Best features: ', best_features_names)\n",
    "    \n",
    "    best_feature = []\n",
    "    for feature_name in best_features_names:\n",
    "        best_feature.append(data[feature_name])\n",
    "    best_feature = pd.DataFrame(best_feature).T\n",
    "    best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features = ['loan_amount', 'loan_payments', 'has_disponent', 'mean_balance', 'min_balance', 'monthly_diff', 'account_frequency_monthly issuance', 'account_frequency_weekly issuance']\n",
    "if SELECT_WRAPPED:\n",
    "    features = list(best_features_names)\n",
    "\n",
    "features_selected = pd.concat([data[features], _data['status']], axis=1)\n",
    "features_selected = pd.concat([_data['loan_id'], features_selected], axis=1)\n",
    "features_selected.to_csv('data_processed/complete/data_selected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
